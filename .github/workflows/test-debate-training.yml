name: Test Debate Training Pipeline

# Workflow for testing the debate training functionality without Kaggle datasets
on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  test-training-pipeline:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pydantic pyyaml typing-extensions
        pip install pandas numpy scikit-learn
        pip install -e .
        
    - name: Create mock datasets for testing
      run: |
        mkdir -p datasets
        
        # Create mock UN General Debates dataset
        cat > datasets/test_un_general_debates.csv << 'EOF'
        country,year,text
        United States,2023,"We believe that multilateral cooperation is essential for addressing global challenges."
        United Kingdom,2023,"The international community must work together to combat climate change."
        France,2023,"Diplomacy and dialogue remain the cornerstone of international relations."
        EOF
        
        # Create mock SOHO Forum dataset
        cat > datasets/test_soho_forum.csv << 'EOF'
        topic,position,debate_result
        Trade Policy,"Free trade promotes economic growth","Pro-trade won 65%"
        Climate Policy,"Market solutions are most effective","Market approach 52%"
        EOF
        
        # Create mock UN Corpus dataset
        cat > datasets/test_un_corpus.csv << 'EOF'
        year,country,speech,topic
        2020,Germany,"International cooperation is vital for global stability","Global Cooperation"
        2021,Japan,"Technology and diplomacy must work together","Tech Diplomacy"
        EOF
        
    - name: Test training script functionality
      run: |
        echo "Testing debate model training script..."
        python scripts/train_debate_model.py
        
    - name: Verify training outputs
      run: |
        # Check that training artifacts were created
        if [ -d "training_output" ]; then
          echo "✅ Training output directory created"
          ls -la training_output/
        else
          echo "❌ Training output directory not found"
          exit 1
        fi
        
        # Check for expected output files
        for file in training_results.json training_data_summary.json training_report.md; do
          if [ -f "training_output/$file" ]; then
            echo "✅ Found $file"
          else
            echo "❌ Missing $file"
            exit 1
          fi
        done
        
    - name: Display training report
      run: |
        echo "=== Training Report ==="
        cat training_output/training_report.md
        
    - name: Upload test artifacts
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-training-artifacts
        path: |
          training_output/
          *.log
        retention-days: 7
        
    - name: Run existing tests to ensure no regressions
      run: |
        python -m pytest tests/test_p0_implementation.py -v